###### Configuration file for the migration assistant ######
### DATABRICKS WORKSPACE PARAMETERS
# The scope where the PAT is stored
DATABRICKS_TOKEN_SECRET_SCOPE: FILL ME IN
# The key underwhich the PAT is stored
DATABRICKS_TOKEN_SECRET_KEY: FILL ME IN
# hostname of the databricks workspaces, eg "https://adb-1231234132.12.azuredatabricks.net" - DO NOT PUT A TRAILING /
DATABRICKS_HOST: FILL ME IN

### VECTOR SEARCH PARAMETERS
# The Vector Search endpoint which will host the index. Endpoint will be created if not found
# and you have the correct permissions.
# see here https://docs.databricks.com/en/generative-ai/vector-search.html#how-to-set-up-mosaic-ai-vector-search
VECTOR_SEARCH_ENDPOINT_NAME: "sql_migration_assistant_vs_endpoint"

# the embedding model name. If not using one of the default Foundation Model APIs this model will need to be served.
# if using foundation model pay per token API, this might be "databricks-gte-large-en"
# otherwise you will need to serve an embedding model. Instructions here:
# https://docs.databricks.com/en/machine-learning/model-serving/create-foundation-model-endpoints.html
# Databricks provides a set of embedding models in the schema catalog.ai for easy hosting from Unity Catalog (the bge* models)
EMBEDDING_MODEL_ENDPOINT_NAME: "sql_migration_assistant_bge_large_en_v1_5"

# the path to the embedding model in the catalog. This is only used if an embedding model serving endpoint is created during setup.
EMBEDDING_MODEL_UC_PATH: "system.ai.bge_large_en_v1_5"


# the  name of the VS index to create. will be placed in the catalog and schema defined above
# change if you don't like the default name
VS_INDEX_NAME : "sql_migration_assistant_code_intent_vs_index"
# the name of table to store the code intent. will be placed in the catalog and schema defined above
# change if you don't like the default name
CODE_INTENT_TABLE_NAME: "sql_migration_assistant_code_intent_table"

### UNITY CATALOG PARAMETERS
# Unity Catalog catalog for storing tables.
# Will be created if does not exist and you have CREATE CATALOG permission.
CATALOG: "main"
# Unity Catalog schema for storing tables
# Will be created if does not exist and you have CREATE SCHEMA permission in the catalog defined above.
SCHEMA: 'sql-migration-assistant'

### SQL WAREHOUSE PARAMETERS
# the http path from the connection details of a SQL Warehouse. This is retreived from the connection details of the SQL
# warehouse page in the Databricks workspace.
# eg "/sql/1.0/warehouses/d1184b8c2a8a87eb"
DEFAULT_SQL_WAREHOUSE_ID:
DEFAULT_SQL_WAREHOUSE_NAME: "sql_migration_assistant_warehouse"
### CHATBOT PARAMETERS
# The foundation model to use. This needs to be a chat model (e.g. one ending in -instruct).
# If not using one of the default Foundation Model APIs this model will need to be served.
# if using foundation model pay per token API, this might be "databricks-meta-llama-3-1-405b-instruct"
# otherwise you will need to serve a foundation model. Instructions here:
# https://docs.databricks.com/en/machine-learning/model-serving/create-foundation-model-endpoints.html
# Databricks provides a set of foundation models in the schema catalog.ai for easy hosting from Unity Catalog.
# You need to serve a model ending in -instruct.
SERVED_FOUNDATION_MODEL_NAME: FILL ME IN
USE_GUARDRAILS: False
# how many tokens is the model allowed to generate.
# Default value.
MAX_TOKENS: 4096
# mlflow experiment name for tracing and logging Replace with your own Databricks user name - experiments must be
# saved in the /Users folder of the workspace and will error if not.
# eg "/Users/<user name>/databricks-project-gamma"
MLFLOW_EXPERIMENT_NAME: FILL ME IN
# mlflow model name. Will be concatenated with the below catalog and schema to create the full model name
# change if you don't like the default name
MLFLOW_MODEL_NAME: "migration-assistant-chain"
# the CPU endpoint to serve the langchain model. Will be created if not found.
# change if you don't like the default name
LANGCHAIN_SERVING_ENDPOINT_NAME: "project-gamma-endpoint"
PROVISIONED_THROUGHPUT_ENDPOINT_NAME: "migration_assistant_endpoint"